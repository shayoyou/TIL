# 📖 **복습 노트: NLP에서의 언어학 적용 사례**  

## 🔍 **1. 자연언어처리(NLP)에서의 언어학 개념 적용**  
자연어처리는 인간이 사용하는 언어를 컴퓨터가 이해하고 처리하는 기술로, 다양한 언어학 개념이 활용됩니다.  

### 🏷️ **1.1 키워드 분석 (Keyword Analysis)**  
- 문서에서 중요한 단어를 추출하여 의미를 분석하는 기법  
- 검색 엔진, 문서 요약, 챗봇 응답 등에 활용  

### 🔡 **1.2 토큰화 (Tokenization)**  
- 문장을 단어 또는 하위 단위(서브워드)로 나누는 과정  
- 대표적인 라이브러리: `spaCy`, `NLTK`, `BERT 토크나이저`  

### 📌 **1.3 품사 태깅 (POS Tagging)**  
- 단어의 품사(명사, 동사, 형용사 등)를 식별하여 태깅하는 과정  
- 문장 구조 분석 및 구문 해석에 필수  

### 🌲 **1.4 구문 분석 (Parsing)**  
- 문장의 문법적 구조를 분석하는 과정  
- **종류**:  
  - **구구조 분석 (Constituency Parsing)**: 문장을 구성 요소로 분할  
  - **의존구문 분석 (Dependency Parsing)**: 단어 간의 의존 관계를 분석  

### 🧠 **1.5 의미/담화 분석 (Semantic & Discourse Analysis)**  
- 문장의 의미를 분석하고, 문맥 내 관계를 파악  
- 감성 분석, 기계 번역 등에 활용  

### 🏷️ **1.6 개체명 인식 (Named Entity Recognition, NER)**  
- 문장에서 고유명사(인물, 장소, 조직 등)를 식별  
- 뉴스 요약, 챗봇, 검색 엔진 등에 사용  

### ✏️ **1.7 문법 교정 (Grammatical Error Correction, GEC)**  
- 문장에서 문법 오류를 자동으로 수정하는 기술  
- AI 기반의 맞춤법 검사기, 자동 교정 시스템에 활용  

---

## 🤖 **2. NLP 모델과 언어학**  
### 🏗 **2.1 BERT와 언어 구조 (What does BERT learn?)**  
- BERT는 언어의 계층적 구조를 반영하여 학습  
  - **하위 계층**: 표면적 특징 (단어 수준)  
  - **중간 계층**: 구문적 특징 (문장 구조)  
  - **상위 계층**: 의미론적 특징  

### 🏷 **2.2 LIMIT-BERT: 언어학 기반 멀티태스크 BERT**  
- 다양한 언어적 지식을 BERT 모델에 적용하여 성능 향상  

### ⚙️ **2.3 GiBERT: 언어적 지식 삽입 기법**  
- 가벼운 방식으로 BERT에 언어학적 정보를 주입하여 성능 개선  

### 🔎 **2.4 인간의 언어 인식과 BERT (Does BERT Learn as Humans Perceive?)**  
- 인간이 인식하는 언어 스타일을 BERT가 학습하는지 분석  

### 💾 **2.5 DMOps: 데이터 관리 및 활용 (Data Management Operation and Recipes)**  
- NLP 모델 학습을 위한 데이터 관리 및 운영 기법  

---

## ✅ **복습 체크리스트**  
✔ 자연어처리에서 키워드 분석과 토큰화의 차이점을 설명할 수 있는가?  
✔ 품사 태깅과 구문 분석의 역할을 이해했는가?  
✔ BERT가 언어 구조를 어떻게 학습하는지 설명할 수 있는가?  
✔ 개체명 인식과 문법 교정 기술이 NLP에서 어떻게 활용되는지 이해했는가?  

---
