## 라이브러리

*   KoNLPy : 한국어 자연어 처리를 위한 대표적 python Library
*   NLTK(Natural Language Toolkit) : 영어로 된 텍스트의 자연 처리를 위한 대표적인 python Library

## 토큰화(Tokenization)

주어진 데이터를 토큰(Token)이라 불리는 단위로 나누는 작업

*   토큰이 되는 기준은 다를 수 있다(어절, 단어, 형태소, 음절, 자소 등)

### 토큰화의 필요성

텍스트를 잘게 나누어 수치화해야 하는데, 어떻게 나누는가에 따라 성능과 학습에 직결이 된다

### 구글이 공개한 Tokenization Tools

*   SentecePiece
    *   특징: Subword 기반 토큰화, BPE(Byte Pair Encoding) 알고리즘 사용

### Subword

하나의 단어를 더 작은 단위의 의미있는 Subword들의 조합으로 분리하는 Tokenization 기법

*   **장점** : OOV(Out-of-Vocabulary) 문제에 효과적으로 대처 가능, 희귀 단어 또는 새로운 단어에 대한 표현력을 높임
*   **예시** : 'unbreakable' -> 'un', 'break', 'able' 로 분리

### Tokenizers

Rust로 만들어진 Tokenizer를 사용할 수 있는 python Library, Hugging Face에서 제공

*   **특징** : 다양한 Subword Tokenization 알고리즘 지원 (BPE, WordPiece, Unigram 등), 빠른 속도, 다양한 모델과의 호환성
*   **장점** : Hugging Face Transformers Library와 함께 사용 시 강력한 성능 발휘

## 정제 (Cleaning)

코퍼스 내에서 토큰화 작업에 방해가 되거나 의미가 없는 부분의 텍스트, 노이즈를 제거하는 작업

*   코퍼스(Corpus)란 자연어 처리(NLP)나 언어학에서 분석, 연구, 또는 학습을 위해 수집된 텍스트 데이터의 집합을 의미. 쉽게 말하면 언어 데이터를 모아둔 데이터셋
*   주로 불용어, 특수문자 제거 / 대.소문자 통합 / 중복 문구 제거 / 다중 공백 통일 등으로 구성

## 정규화(Normalization)

*   Stemming(어간 추출)

    *   예)
        *   formalize → formal
        *   allowance → allow
        *   electrical → electric
        *   먹었다(ate), 먹을(will eat) → 먹다(eat)
*   Lemmatization (표제어 추출)
    *   예)
        *   Cats → cat(어간) + s(접사)
        *   Dies → die
        *   Watched → watch
        *   Has → have

## 편집 거리 (Edit distance)

Levenshtein distance (레벤슈타인 거리)

*   한 문자열을 다른 문자열로 변환할 때 필요한 최소한의 연산 횟수를 의미
*   횟수(거리)가 낮을수록 유사한 문자열로 판단

### 편집 연산

*   삽입 (Insertion) → 문자 추가
*   삭제 (Deletion) → 문자 제거
*   대체 (Substitution) → 문자 변경

### 편집 거리 예시

kitten → sitting 변환 과정

*   kitten → sitten (k → s, 대체)
*   sitten → sittin (e → i, 대체)
*   sittin → sitting (g 추가, 삽입)
*   따라서 Levenshtein 거리 = 3 (대체 2번 + 삽입 1번)

## 정규표현식(Regex)

많이 연습해보세요!
