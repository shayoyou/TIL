# 비지도학습

## 비지도학습이란?

비지도 학습은 머신 러닝의 한 유형으로, 레이블이 지정되지 않은 데이터를 사용하여 학습하는 알고리즘입니다. 즉, 입력 데이터에 대한 출력 값이나 정답이 주어지지 않은 상태에서 데이터 자체의 구조, 패턴, 특징을 파악하는 것을 목표로 합니다.

## 군집화 (Clustering)

유사한 특징을 가진 데이터들을 그룹으로 묶는 작업입니다. 쉽게 말해, 레이블이나 정답 없이 데이터들끼리의 유사성을 기반으로 끼리끼리 묶어주는 것이죠.

K-평균 알고리즘 (K-means clustering): 가장 널리 사용되는 알고리즘 중 하나입니다. 데이터를 K개의 군집으로 나누고, 각 데이터를 가장 가까운 군집 중심에 할당하는 방식으로 동작합니다.

계층적 군집화 (Hierarchical clustering): 데이터 간의 거리를 기반으로 계층적인 트리 구조를 형성하는 알고리즘입니다. 덴드로그램을 통해 군집 구조를 시각적으로 확인할 수 있습니다.

DBSCAN (Density-Based Spatial Clustering of Applications with Noise): 데이터의 밀도를 기반으로 군집을 형성하는 알고리즘입니다. 노이즈에 강하고, 다양한 형태의 군집을 찾을 수 있다는 장점이 있습니다.

## 매니폴드 가설 (Manifold Hypothesis)

매니폴드 가설은 고차원 데이터가 실제로는 저차원의 매니폴드에 존재한다는 가정입니다.

**고차원 데이터**:

우리가 일상에서 접하는 데이터는 대부분 고차원입니다. 예를 들어, 이미지는 수많은 픽셀로 이루어져 있고, 텍스트는 수많은 단어로 이루어져 있습니다. 이처럼 많은 변수로 이루어진 데이터를 고차원 데이터라고 합니다.

**저차원 매니폴드**:

매니폴드는 쉽게 말해 "굽어진 공간"입니다. 예를 들어, 지구 표면은 3차원 공간에 존재하지만, 실제로는 2차원 평면처럼 움직일 수 있습니다. 이처럼 고차원 공간에 존재하지만 실제로는 더 낮은 차원의 구조를 가지는 공간을 매니폴드라고 합니다.

**매니폴드 가설**:

매니폴드 가설은 고차원 데이터가 실제로는 저차원 매니폴드에 존재한다고 가정합니다. 즉, 복잡해 보이는 고차원 데이터도 실제로는 훨씬 단순한 구조를 가지고 있다는 것입니다.

**매니폴드 가설의 중요성**:

매니폴드 가설은 머신 러닝, 특히 차원 축소 및 데이터 시각화 분야에서 매우 중요한 역할을 합니다. 고차원 데이터를 저차원 매니폴드로 표현함으로써 데이터의 복잡성을 줄이고, 데이터 분석 및 시각화를 용이하게 할 수 있습니다.

**매니폴드 학습**:

매니폴드 학습은 매니폴드 가설을 기반으로 고차원 데이터를 저차원 매니폴드로 표현하는 알고리즘입니다. 대표적인 매니폴드 학습 알고리즘으로는 PCA (Principal Component Analysis), t-SNE (t-distributed Stochastic Neighbor Embedding) 등이 있습니다.


## 차원축소 (Dimensionality Reduction)

고차원 데이터의 정보를 최대한 보존하면서 훨씬 적은 차원으로 표현할 수 있는 방법을 찾는 것.
- PCA (주성분분석, Principal Component Analysis)

## 시각화 (Visualization)

고차원의 데이터를 차원 축소해 그 구조를 사람이 알기 쉽도록 보여주는 방법
- t-SNE (t-distributed Stochastic Neighbor Embedding)

## 노이즈 제거 (Denoising)

차원 축소를 하면 정보가 유실된다는 사실을 역으로 이용해, 원본 데이터의 노이즈를 제거하는 방식으로 활용할 수도 있다.

## 이상값 탐지 (Anomaly Detection)

일반적인 인풋값과 전혀 다른, 이상값을 찾아내는 문제  
매니폴드 구조를 학습하고 거기에서 벗어나 있는 데이터 포인트를 찾는다

- 엑스레이 사진들을 모아둔 데이터셋에서, 목걸이를 하고 찍은 것 등 판독불가 샘플을 걸러내기
- 공장 컨베이어 벨트에서 센서 데이터를 통해 불량품을 확인하기

## 임베딩 공간의 활용: 단어의 임베딩 (Word to Vector)

Word to vector(단어 임베딩)는 자연어 처리(NLP)에서 텍스트를 숫자로 변환하는 데 사용되는 중요한 기술입니다. 쉽게 말해, 단어를 컴퓨터가 이해할 수 있는 숫자 형태로 바꾸는 것이죠.

좀 더 자세히 설명하면, 단어 임베딩은 단어를 벡터 공간에 매핑하는 것을 의미합니다. 각 단어는 벡터 공간에서 특정 위치를 갖는 벡터로 표현되며, 이 벡터는 단어의 의미와 문맥 정보를 담고 있습니다.

## 생성모델 (generative model): Variational Autoencoders (VAEs)

저차원 임베딩 공간에서 원래의 이미지 공간으로 가는 함수를 학습해, 기존에 없던, 새로운 feature를 가진 샘플을 만들어낸다.